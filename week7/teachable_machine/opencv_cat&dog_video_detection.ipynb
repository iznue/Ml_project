{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teachable Machine을 이용한 cat&dog detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model('keras_model_cat_dog.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Video Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length :  418\n",
      "width :  960\n",
      "height :  540\n",
      "fps :  25.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('cat&dog.mp4')\n",
    "if not cap.isOpened():\n",
    "  print(\"could not open :\", infilename)\n",
    "  exit(0)\n",
    " \n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))   # 영상의 전체프레임수(한장한장사진의 전체갯수)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))    # 영상너비\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 영상 높이\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)                  # frame per second (초당 프레임수) 24개\n",
    " \n",
    "print('length : ', length)\n",
    "print('width : ', width)\n",
    "print('height : ', height)\n",
    "print('fps : ', fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply keras_model_cat_dog.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def model_dab(img):\n",
    "  re=img.reshape(1,224,224,3)     # 텐서에 넣기 위해서 맨앞 1을 확장함. (180,180,3)사진을\n",
    "  predict=model.predict(re)       # 모델을 예측함. softmax함수에 의해서 3가지 경우의 수의 확률값이 출력됨\n",
    "  predict_num=np.argmax(predict)       # 3개의 확률중 가장 큰 값을 갖고 있는 위치값을 갖고옴\n",
    "\n",
    "  class_name=['cat', 'dog']\n",
    "  return class_name[predict_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캡처된 사진 저장용 폴더\n",
    "\n",
    "def save_folder(folder):\n",
    "  import os\n",
    "  import shutil\n",
    "\n",
    "  MODEL_DIR = './' + folder + '/'\n",
    "  # 폴더삭제(자료가 있어도 삭제함)\n",
    "  if os.path.exists(MODEL_DIR):\n",
    "      shutil.rmtree(MODEL_DIR)\n",
    "\n",
    "  # 새로 폴더만듦\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 프레임 저장\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "face=[]\n",
    "vidcap = cv2.VideoCapture('c:/Users/user/Desktop/mtvs/week7/teachable_machine/cat&dog.mp4')\n",
    "folderName='face_caputre_모든프레임'\n",
    "save_folder(folderName)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(vidcap.isOpened()):\n",
    "    try:\n",
    "      ret, image = vidcap.read()\n",
    "      img=cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)  # 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\n",
    "      resize_frame = cv2.resize(img, (180, 180))   #사이즈 조정 180,180으로\n",
    "      result=model_dab(resize_frame)  #모델에 넣어서 결과보기\n",
    "      fileName='./'+folderName +'/' +  result + '_' + str(count).zfill(3)+ '.jpg'\n",
    "      cv2.imwrite(fileName,resize_frame)\n",
    "      face.append(result)\n",
    "      count += 1\n",
    "      \n",
    "    except:\n",
    "      break\n",
    " \n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 180, 180, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m# img=cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)  # 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m resize_frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, (\u001b[39m180\u001b[39m, \u001b[39m180\u001b[39m))   \u001b[39m#사이즈 조정 180,180으로\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m result\u001b[39m=\u001b[39mmodel_dab(resize_frame)  \u001b[39m#모델에 넣어서 결과보기\u001b[39;00m\n\u001b[0;32m     22\u001b[0m fileName\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfolderName \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m  result \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(count)\u001b[39m.\u001b[39mzfill(\u001b[39m3\u001b[39m)\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     23\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(fileName,resize_frame)\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mmodel_dab\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_dab\u001b[39m(img):\n\u001b[0;32m      4\u001b[0m   re\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m180\u001b[39m,\u001b[39m180\u001b[39m,\u001b[39m3\u001b[39m)     \u001b[39m# 텐서에 넣기 위해서 맨앞 1을 확장함. (180,180,3)사진을\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m   predict\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mpredict(re)       \u001b[39m# 모델을 예측함. softmax함수에 의해서 3가지 경우의 수의 확률값이 출력됨\u001b[39;00m\n\u001b[0;32m      6\u001b[0m   predict_num\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(predict)       \u001b[39m# 3개의 확률중 가장 큰 값을 갖고 있는 위치값을 갖고옴\u001b[39;00m\n\u001b[0;32m      8\u001b[0m   class_name\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "face_second=[]\n",
    "vidcap = cv2.VideoCapture('cat&dog.mp4')\n",
    "folderName='face_caputre_초당1장'\n",
    "save_folder(folderName)\n",
    "\n",
    "\n",
    "count = 0\n",
    " \n",
    "while(vidcap.isOpened()):\n",
    "    try:\n",
    "      ret, image = vidcap.read()\n",
    "      # print(ret)\n",
    "      # print(image)\n",
    "      if count%25==0:\n",
    "        print(count)\n",
    "\n",
    "        # img=cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)  # 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\n",
    "        resize_frame = cv2.resize(image, (180, 180))   #사이즈 조정 180,180으로\n",
    "        result=model_dab(resize_frame)  #모델에 넣어서 결과보기\n",
    "        fileName='./'+folderName +'/' +  result + '_' + str(count).zfill(3)+ '.jpg'\n",
    "        cv2.imwrite(fileName,resize_frame)\n",
    "        face_second.append(result)\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "    except:\n",
    "      break\n",
    " \n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "face_second=[]\n",
    "vidcap = cv2.VideoCapture('cat&dog.mp4')\n",
    "folderName='face_caputre_초당1장'\n",
    "save_folder(folderName)\n",
    "\n",
    "\n",
    "count = 0\n",
    " \n",
    "while(vidcap.isOpened()):\n",
    "    ret, image = vidcap.read()\n",
    "      \n",
    "    if count%25==0:\n",
    "        print(count)\n",
    "\n",
    "        img=cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)  # 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\n",
    "        resize_frame = cv2.resize(img, (224, 224))   #사이즈 조정 180,180으로\n",
    "        result=model_dab(resize_frame)  #모델에 넣어서 결과보기\n",
    "        fileName='./'+folderName +'/' +  result + '_' + str(count).zfill(3)+ '.jpg'\n",
    "        cv2.imwrite(fileName,resize_frame)\n",
    "        face_second.append(result)\n",
    "\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    " \n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     ret, image \u001b[39m=\u001b[39m vidcap\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> 13\u001b[0m     img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mrotate(image, cv2\u001b[39m.\u001b[39;49mcv2\u001b[39m.\u001b[39mROTATE_90_CLOCKWISE)  \u001b[39m# 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     resize_frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m180\u001b[39m, \u001b[39m180\u001b[39m))   \u001b[39m#사이즈 조정 180,180으로\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     result\u001b[39m=\u001b[39mmodel_dab(resize_frame)  \u001b[39m#모델에 넣어서 결과보기\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'cv2'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "face_second=[]\n",
    "vidcap = cv2.VideoCapture('cat&dog.mp4')\n",
    "folderName='face_caputre_초당1장'\n",
    "save_folder(folderName)\n",
    "\n",
    "count = 0\n",
    "\n",
    "if vidcap.isOpened():\n",
    "    while True:\n",
    "        ret, image = vidcap.read()\n",
    "        img=cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)  # 원본영상이 회전되어 있는 영상이라 우측으로90도 회전함(상황에 따라 작업함)\n",
    "        resize_frame = cv2.resize(img, (180, 180))   #사이즈 조정 180,180으로\n",
    "        result=model_dab(resize_frame)  #모델에 넣어서 결과보기\n",
    "        fileName='./'+folderName +'/' +  result + '_' + str(count).zfill(3)+ '.jpg'\n",
    "        cv2.imwrite(fileName,resize_frame)\n",
    "        face.append(result)\n",
    "        count += 1\n",
    "else:\n",
    "    print('cant open video')\n",
    "\n",
    "vidcap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
