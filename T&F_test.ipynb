{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 577ms/step\n",
      "Face Class: F\n",
      "Confidence Score: 0.5738353\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_Model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = ['T', 'F']\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image_path = \"20293_20326_517.jpg\"\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# MediaPipe 얼굴 인식 모듈 초기화\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# Convert PIL image to OpenCV image (numpy array)\n",
    "image_cv = np.array(image)\n",
    "image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Detect faces using MediaPipe\n",
    "results = face_detection.process(image_cv)\n",
    "if results.detections:\n",
    "    for detection in results.detections:\n",
    "        bboxC = detection.location_data.relative_bounding_box\n",
    "        ih, iw, _ = image_cv.shape\n",
    "        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "        cropped_face = image_cv[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the cropped face to 224x224\n",
    "        resized_face = cv2.resize(cropped_face, (224, 224))\n",
    "        \n",
    "        # Normalize the image\n",
    "        normalized_image_array = (resized_face.astype(np.float32) / 127.5) - 1\n",
    "        \n",
    "        # Load the normalized image into the array\n",
    "        data[0] = normalized_image_array\n",
    "        \n",
    "        # Predict the model\n",
    "        prediction = model.predict(data)\n",
    "        index = np.argmax(prediction)\n",
    "        class_name = class_names[index]\n",
    "        confidence_score = prediction[0][index]\n",
    "        \n",
    "        # Print prediction and confidence score for this face\n",
    "        print(\"Face Class:\", class_name)\n",
    "        print(\"Confidence Score:\", confidence_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
