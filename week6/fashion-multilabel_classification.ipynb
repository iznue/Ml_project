{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Label Classificaiton-Fashion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "     year   usage                             productDisplayName  \n",
       "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
       "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
       "2  2016.0  Casual                       Titan Women Silver Watch  \n",
       "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
       "4  2012.0  Casual                          Puma Men Grey T-shirt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('c:/data/multilabel_fashion/styles.csv', on_bad_lines='skip')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'masterCategory', 'subCategory', 'articleType',\n",
       "       'baseColour', 'season', 'year', 'usage', 'productDisplayName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.nunique()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "['Men' 'Women' 'Boys' 'Girls' 'Unisex']\n",
      "-------------------------\n",
      "masterCategory\n",
      "['Apparel' 'Accessories' 'Footwear' 'Personal Care' 'Free Items'\n",
      " 'Sporting Goods' 'Home']\n",
      "-------------------------\n",
      "subCategory\n",
      "['Topwear' 'Bottomwear' 'Watches' 'Socks' 'Shoes' 'Belts' 'Flip Flops'\n",
      " 'Bags' 'Innerwear' 'Sandal' 'Shoe Accessories' 'Fragrance' 'Jewellery'\n",
      " 'Lips' 'Saree' 'Eyewear' 'Scarves' 'Dress' 'Loungewear and Nightwear'\n",
      " 'Wallets' 'Apparel Set' 'Headwear' 'Mufflers' 'Skin Care' 'Makeup'\n",
      " 'Free Gifts' 'Ties' 'Accessories' 'Nails' 'Beauty Accessories'\n",
      " 'Water Bottle' 'Skin' 'Eyes' 'Bath and Body' 'Gloves'\n",
      " 'Sports Accessories' 'Cufflinks' 'Sports Equipment' 'Stoles' 'Hair'\n",
      " 'Perfumes' 'Home Furnishing' 'Umbrellas' 'Wristbands' 'Vouchers']\n",
      "-------------------------\n",
      "articleType\n",
      "['Shirts' 'Jeans' 'Watches' 'Track Pants' 'Tshirts' 'Socks' 'Casual Shoes'\n",
      " 'Belts' 'Flip Flops' 'Handbags' 'Tops' 'Bra' 'Sandals' 'Shoe Accessories'\n",
      " 'Sweatshirts' 'Deodorant' 'Formal Shoes' 'Bracelet' 'Lipstick' 'Flats'\n",
      " 'Kurtas' 'Waistcoat' 'Sports Shoes' 'Shorts' 'Briefs' 'Sarees'\n",
      " 'Perfume and Body Mist' 'Heels' 'Sunglasses' 'Innerwear Vests' 'Pendant'\n",
      " 'Laptop Bag' 'Scarves' 'Dresses' 'Night suits' 'Skirts' 'Wallets'\n",
      " 'Blazers' 'Ring' 'Kurta Sets' 'Clutches' 'Shrug' 'Backpacks' 'Caps'\n",
      " 'Trousers' 'Earrings' 'Camisoles' 'Boxers' 'Jewellery Set' 'Dupatta'\n",
      " 'Capris' 'Lip Gloss' 'Bath Robe' 'Mufflers' 'Tunics' 'Jackets' 'Trunk'\n",
      " 'Lounge Pants' 'Face Wash and Cleanser' 'Necklace and Chains'\n",
      " 'Duffel Bag' 'Sports Sandals' 'Foundation and Primer' 'Sweaters'\n",
      " 'Free Gifts' 'Trolley Bag' 'Tracksuits' 'Swimwear' 'Shoe Laces'\n",
      " 'Fragrance Gift Set' 'Bangle' 'Nightdress' 'Ties' 'Baby Dolls' 'Leggings'\n",
      " 'Highlighter and Blush' 'Travel Accessory' 'Kurtis' 'Mobile Pouch'\n",
      " 'Messenger Bag' 'Lip Care' 'Nail Polish' 'Eye Cream' 'Accessory Gift Set'\n",
      " 'Beauty Accessory' 'Jumpsuit' 'Kajal and Eyeliner' 'Water Bottle'\n",
      " 'Suspenders' 'Face Moisturisers' 'Lip Liner' 'Robe' 'Salwar and Dupatta'\n",
      " 'Patiala' 'Stockings' 'Eyeshadow' 'Headband' 'Tights' 'Nail Essentials'\n",
      " 'Churidar' 'Lounge Tshirts' 'Face Scrub and Exfoliator' 'Lounge Shorts'\n",
      " 'Gloves' 'Wristbands' 'Tablet Sleeve' 'Ties and Cufflinks' 'Footballs'\n",
      " 'Compact' 'Stoles' 'Shapewear' 'Nehru Jackets' 'Salwar' 'Cufflinks'\n",
      " 'Jeggings' 'Hair Colour' 'Concealer' 'Rompers' 'Sunscreen' 'Booties'\n",
      " 'Mask and Peel' 'Waist Pouch' 'Hair Accessory' 'Body Lotion' 'Rucksacks'\n",
      " 'Basketballs' 'Lehenga Choli' 'Clothing Set' 'Mascara' 'Cushion Covers'\n",
      " 'Key chain' 'Rain Jacket' 'Toner' 'Lip Plumper' 'Umbrellas'\n",
      " 'Face Serum and Gel' 'Hat' 'Mens Grooming Kit' 'Makeup Remover'\n",
      " 'Body Wash and Scrub' 'Suits' 'Ipad']\n",
      "-------------------------\n",
      "baseColour\n",
      "['Navy Blue' 'Blue' 'Silver' 'Black' 'Grey' 'Green' 'Purple' 'White'\n",
      " 'Beige' 'Brown' 'Bronze' 'Teal' 'Copper' 'Pink' 'Off White' 'Maroon'\n",
      " 'Red' 'Khaki' 'Orange' 'Yellow' 'Charcoal' 'Gold' 'Steel' 'Tan' 'Multi'\n",
      " 'Magenta' 'Lavender' 'Sea Green' 'Cream' 'Peach' 'Olive' 'Skin'\n",
      " 'Burgundy' 'Coffee Brown' 'Grey Melange' 'Rust' 'Rose' 'Lime Green'\n",
      " 'Mauve' 'Turquoise Blue' 'Metallic' 'Mustard' 'Taupe' 'Nude'\n",
      " 'Mushroom Brown' 'Fluorescent Green']\n",
      "-------------------------\n",
      "season\n",
      "['Fall' 'Summer' 'Winter' 'Spring']\n",
      "-------------------------\n",
      "year\n",
      "[2011. 2012. 2016. 2017. 2015. 2014. 2010. 2013. 2018. 2019. 2007. 2009.\n",
      " 2008.]\n",
      "-------------------------\n",
      "usage\n",
      "['Casual' 'Ethnic' 'Formal' 'Sports' 'Smart Casual' 'Travel' 'Party'\n",
      " 'Home']\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Looking at all the unique labels in all categorical columns \n",
    "cat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType','baseColour', 'season', 'year', 'usage']\n",
    "\n",
    "for col in cat_columns:\n",
    "    print(col)\n",
    "    print(df[col].unique())\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article types used:  Index(['Tshirts', 'Shirts', 'Casual Shoes', 'Watches', 'Sports Shoes',\n",
      "       'Kurtas', 'Tops', 'Handbags', 'Heels', 'Sunglasses'],\n",
      "      dtype='object', name='articleType')\n"
     ]
    }
   ],
   "source": [
    "value_counts = df['articleType'].value_counts()\n",
    "\n",
    "indexes = value_counts.index\n",
    "\n",
    "values = value_counts.values\n",
    "\n",
    "for i in range(len(value_counts)):\n",
    "\n",
    "    if values[i] <1000:\n",
    "        break\n",
    "\n",
    "types_used = indexes[:i]\n",
    "print('Article types used: ',types_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Colours used:  Index(['Black', 'White', 'Blue', 'Brown', 'Grey', 'Red', 'Green', 'Pink',\n",
      "       'Navy Blue', 'Purple', 'Silver'],\n",
      "      dtype='object', name='baseColour')\n"
     ]
    }
   ],
   "source": [
    "value_counts = df['baseColour'].value_counts()\n",
    "\n",
    "indexes = value_counts.index\n",
    "\n",
    "values = value_counts.values\n",
    "\n",
    "for i in range(len(value_counts)):\n",
    "\n",
    "    if values[i] <1000:\n",
    "        break\n",
    "\n",
    "colours_used = indexes[:i]\n",
    "print('Base Colours used: ',colours_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the examples with labels other than the selected ones\n",
    " \n",
    "df = df[df['articleType'].isin(types_used)]\n",
    "df = df[df['baseColour'].isin(colours_used)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21835"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of examples we are left with\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Reading all the images and processing the data in them \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "\n",
    "IX = 80\n",
    "IY = 60\n",
    "\n",
    "invalid_ids = []\n",
    "\n",
    "for name in df.id:\n",
    "\n",
    "    try:\n",
    "        image = cv2.imread('c:/data/multilabel_fashion/images/'+str(name)+'.jpg')\n",
    "        image = cv2.resize(image, (IX,IY) )\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)        \n",
    "    except: \n",
    "        # Images for certain ids are missing, so they are not added to the dataset  \n",
    "        invalid_ids.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid ids:\n",
      "[39403, 39425]\n"
     ]
    }
   ],
   "source": [
    "# ids of missing images\n",
    "print('invalid ids:')\n",
    "print(invalid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "used_columns = ['subCategory','baseColour']\n",
    "\n",
    "# getting labels for the columns used\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    if row['id'] in invalid_ids:\n",
    "        continue\n",
    "\n",
    "    tags = []\n",
    "\n",
    "    for col in used_columns:\n",
    "        tags.append(row[col])\n",
    "\n",
    "    labels.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Topwear' 'Navy Blue']\n",
      " ['Watches' 'Silver']\n",
      " ['Topwear' 'Grey']\n",
      " ...\n",
      " ['Shoes' 'White']\n",
      " ['Topwear' 'Blue']\n",
      " ['Watches' 'Pink']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# converting data into numpy arrays\n",
    "\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bags' 'Belts' 'Black' 'Blue' 'Brown' 'Eyewear' 'Free Gifts' 'Green'\n",
      " 'Grey' 'Navy Blue' 'Pink' 'Purple' 'Red' 'Shoes' 'Silver' 'Topwear'\n",
      " 'Watches' 'White']\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# creating a binary vector for the input labels \n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "print(mlb.classes_)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "inputShape = (IY, IX, 3)\n",
    "\n",
    "# A very simple sequential model is used since the images are very low resolution and the categories are fiarly distinct\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "out = len(mlb.classes_)\n",
    "\n",
    "model.add(Dense(out))\n",
    "model.add(Activation('sigmoid')) # activation function for the final layer has to be sigmoid, since mutiple output labels can have value 1\n",
    "                    \n",
    "model.compile(loss='binary_crossentropy', # loss function has to be binary_crossentropy, it is calculated seperately for each of the outputs\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data into testing and training set \n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "615/615 [==============================] - 12s 6ms/step - loss: 0.1959 - mse: 0.0547\n",
      "Epoch 2/50\n",
      "615/615 [==============================] - 3s 6ms/step - loss: 0.1044 - mse: 0.0288\n",
      "Epoch 3/50\n",
      "615/615 [==============================] - 3s 6ms/step - loss: 0.0880 - mse: 0.0245\n",
      "Epoch 4/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0802 - mse: 0.0225\n",
      "Epoch 5/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0746 - mse: 0.0209\n",
      "Epoch 6/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0715 - mse: 0.0201\n",
      "Epoch 7/50\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0681 - mse: 0.0192\n",
      "Epoch 8/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0649 - mse: 0.0183\n",
      "Epoch 9/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0624 - mse: 0.0176\n",
      "Epoch 10/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0595 - mse: 0.0168\n",
      "Epoch 11/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0574 - mse: 0.0162\n",
      "Epoch 12/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0547 - mse: 0.0154\n",
      "Epoch 13/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0525 - mse: 0.0148\n",
      "Epoch 14/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0511 - mse: 0.0144\n",
      "Epoch 15/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0487 - mse: 0.0137\n",
      "Epoch 16/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0462 - mse: 0.0130\n",
      "Epoch 17/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0441 - mse: 0.0123\n",
      "Epoch 18/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0424 - mse: 0.0118\n",
      "Epoch 19/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0410 - mse: 0.0114\n",
      "Epoch 20/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0391 - mse: 0.0108\n",
      "Epoch 21/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0375 - mse: 0.0103\n",
      "Epoch 22/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0358 - mse: 0.0099\n",
      "Epoch 23/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0344 - mse: 0.0094\n",
      "Epoch 24/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0331 - mse: 0.0091\n",
      "Epoch 25/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0315 - mse: 0.0086\n",
      "Epoch 26/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0307 - mse: 0.0084\n",
      "Epoch 27/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0294 - mse: 0.0080\n",
      "Epoch 28/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0275 - mse: 0.0074\n",
      "Epoch 29/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0272 - mse: 0.0074\n",
      "Epoch 30/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0262 - mse: 0.0071\n",
      "Epoch 31/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0248 - mse: 0.0067\n",
      "Epoch 32/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0239 - mse: 0.0064\n",
      "Epoch 33/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0231 - mse: 0.0062\n",
      "Epoch 34/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0226 - mse: 0.0060\n",
      "Epoch 35/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0220 - mse: 0.0059\n",
      "Epoch 36/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0217 - mse: 0.0058\n",
      "Epoch 37/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0202 - mse: 0.0053\n",
      "Epoch 38/50\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.0197 - mse: 0.0052\n",
      "Epoch 39/50\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.0188 - mse: 0.0049\n",
      "Epoch 40/50\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.0184 - mse: 0.0048\n",
      "Epoch 41/50\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.0181 - mse: 0.0048\n",
      "Epoch 42/50\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.0194 - mse: 0.0051\n",
      "Epoch 43/50\n",
      "615/615 [==============================] - 3s 6ms/step - loss: 0.0166 - mse: 0.0043\n",
      "Epoch 44/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0158 - mse: 0.0041\n",
      "Epoch 45/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0156 - mse: 0.0040\n",
      "Epoch 46/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0178 - mse: 0.0047\n",
      "Epoch 47/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0148 - mse: 0.0038\n",
      "Epoch 48/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0152 - mse: 0.0040\n",
      "Epoch 49/50\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0147 - mse: 0.0038\n",
      "Epoch 50/50\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0137 - mse: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5f7b1b7f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 32\n",
    "E = 50\n",
    "\n",
    "#training the model \n",
    "model.fit(x=trainX,y=trainY,\n",
    "          epochs=E ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  3674\n",
      "missing/wrong:  694\n",
      "Accuracy:  0.8411172161172161\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(testX)\n",
    "\n",
    "\n",
    "# since the predictions of the model are sigmoid, we will first binarize them to 0 or 1\n",
    "pred_binarized = []\n",
    "\n",
    "for pred in preds:\n",
    "    vals = []\n",
    "    for val in pred:\n",
    "        if val > 0.5:\n",
    "            vals.append(1)\n",
    "        else:\n",
    "            vals.append(0)\n",
    "    pred_binarized.append(vals) \n",
    "\n",
    "pred_binarized = np.array(pred_binarized)   \n",
    "\n",
    "\n",
    "# we convert the output vectors to the predicted labels\n",
    "true_test_labels = mlb.inverse_transform(testY)\n",
    "pred_test_labels = mlb.inverse_transform(pred_binarized)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "# Evaluating the predictions of the model\n",
    "\n",
    "for i in range(len(testY)):\n",
    "\n",
    "    true_labels = list(true_test_labels[i])\n",
    "\n",
    "    pred_labels = list(pred_test_labels[i])\n",
    "\n",
    "    label1 = true_labels[0]\n",
    "    label2 = true_labels[1]\n",
    "\n",
    "    if label1 in pred_labels:\n",
    "        correct+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "\n",
    "    if label2 in pred_labels:\n",
    "        correct+=1\n",
    "    else:\n",
    "        wrong+=1    \n",
    "\n",
    "\n",
    "\n",
    "print('correct: ', correct)\n",
    "print('missing/wrong: ', wrong)\n",
    "print('Accuracy: ',correct/(correct+wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels:  ('Topwear', 'White')  Predicted labels:  ('Topwear', 'White')\n",
      "True labels:  ('Black', 'Shoes')  Predicted labels:  ('Shoes',)\n",
      "True labels:  ('Green', 'Topwear')  Predicted labels:  ('Green', 'Topwear')\n",
      "True labels:  ('Purple', 'Topwear')  Predicted labels:  ('Purple', 'Topwear')\n",
      "True labels:  ('Green', 'Topwear')  Predicted labels:  ('Green', 'Topwear')\n",
      "True labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes', 'White')\n",
      "True labels:  ('Brown', 'Shoes')  Predicted labels:  ('Brown', 'Shoes')\n",
      "True labels:  ('Black', 'Watches')  Predicted labels:  ('Black', 'Watches')\n",
      "True labels:  ('Black', 'Watches')  Predicted labels:  ('Black', 'Watches')\n",
      "True labels:  ('Red', 'Topwear')  Predicted labels:  ('Brown', 'Topwear')\n",
      "True labels:  ('Brown', 'Shoes')  Predicted labels:  ('Brown', 'Shoes')\n",
      "True labels:  ('Black', 'Shoes')  Predicted labels:  ('Black', 'Shoes')\n",
      "True labels:  ('Bags', 'Brown')  Predicted labels:  ('Bags', 'Brown')\n",
      "True labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes', 'White')\n",
      "True labels:  ('Black', 'Topwear')  Predicted labels:  ('Black', 'Topwear')\n",
      "True labels:  ('Black', 'Shoes')  Predicted labels:  ('Black', 'Shoes')\n",
      "True labels:  ('Red', 'Topwear')  Predicted labels:  ('Red', 'Topwear')\n",
      "True labels:  ('Shoes', 'White')  Predicted labels:  ('Shoes',)\n",
      "True labels:  ('Blue', 'Topwear')  Predicted labels:  ('Blue', 'Topwear')\n",
      "True labels:  ('Bags', 'Black')  Predicted labels:  ('Bags', 'Black')\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('True labels: ',true_test_labels[i],' Predicted labels: ',pred_test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
